# BT4222 Mining Web Data for Business Insights
## Movie Box Office Prediction Project

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![Status](https://img.shields.io/badge/Status-Complete-green.svg)

A comprehensive machine learning project developed for the **BT4222 Mining Web Data for Business Insights** course at the National University of Singapore (NUS). This project focuses on predicting movie box office performance using advanced web scraping techniques and machine learning models.

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Key Features](#key-features)
- [Tasks](#tasks)
- [Installation](#installation)
- [Usage](#usage)
- [Methodology](#methodology)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Project Overview

This project tackles the challenge of predicting movie box office performance through two distinct but complementary approaches:

1. **Opening Weekend Gross Prediction**: Predicting a movie's opening weekend revenue based on pre-release information
2. **Time Series Gross Prediction**: Forecasting daily box office performance for movies already in theaters

The project demonstrates advanced web scraping techniques, feature engineering, and the application of both traditional machine learning and deep learning models to real-world business problems in the entertainment industry.

## ğŸ“Š Dataset

### Data Sources
Our comprehensive dataset was constructed by scraping multiple authoritative sources:

- **[The Numbers](https://www.the-numbers.com/)**: Primary source for box office data, including daily gross, opening weekend performance, production budgets, and detailed movie metadata
- **[TMDB (The Movie Database)](https://www.themoviedb.org/)**: Movie metadata, cast and crew information, genres, and additional production details
- **[Wikipedia](https://www.wikipedia.org/)**: Supplementary movie information and validation data

### Dataset Coverage
- **Time Period**: 2000-2025 (with focus on 2020-2025 for primary analysis)
- **Movies**: 3,000+ unique films
- **Features**: 50+ engineered features per movie
- **Records**: 100,000+ daily box office observations

### Key Features
- **Financial**: Production budget, opening weekend gross, daily gross revenue
- **Temporal**: Release dates, days in release, weekend indicators
- **Content**: Genres, keywords, synopsis, running time
- **Production**: Directors, actors, production companies, countries
- **Technical**: Production method (live action/animation), creative type
- **Market**: MPAA ratings, distributor information

## ğŸ“ Project Structure

```
BT4222/
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ BT4222_report.pdf                   # Comprehensive project report
â”œâ”€â”€ instructions.txt                    # Project overview and instructions
â”‚
â”œâ”€â”€ Preprocessing/                      # Data collection and preprocessing
â”‚   â”œâ”€â”€ step1_theNumbers_scraping_daily_gross_2020_2025.ipynb
â”‚   â”œâ”€â”€ step2_TMDB_scraping_2020_2025.ipynb
â”‚   â”œâ”€â”€ step3_theNumbers_scraping_2000_2025.ipynb
â”‚   â””â”€â”€ step4_Wikipedia_TMDB_scraping_2000_2025.ipynb
â”‚
â”œâ”€â”€ Opening Weekend Gross prediction/   # Task 1: Opening weekend prediction
â”‚   â””â”€â”€ opening_weekend_gross_prediction.ipynb
â”‚
â””â”€â”€ Time Series Gross Prediction/       # Task 2: Time series forecasting
    â””â”€â”€ TimeSeriesMovieGrossPrediction.ipynb
```

## âœ¨ Key Features

### Advanced Web Scraping
- **Robust Anti-Bot Protection**: CloudScraper implementation to bypass Cloudflare protection
- **Rate Limiting**: Intelligent request throttling to respect website policies
- **Error Handling**: Comprehensive exception handling and retry mechanisms
- **Multi-Source Integration**: Seamless data fusion from multiple APIs and websites

### Feature Engineering
- **Text Processing**: TF-IDF vectorization of movie synopses and keywords
- **Temporal Features**: Time-based features including lagged variables and rolling windows
- **Categorical Encoding**: One-hot encoding for genres, production companies, and cast/crew
- **Financial Transformations**: Log transformations and percentage-based features

### Machine Learning Pipeline
- **Data Preprocessing**: Robust handling of missing values and outliers
- **Feature Selection**: Automated selection of most predictive features
- **Model Ensemble**: Multiple algorithm comparison and selection
- **Cross-Validation**: Time-aware validation strategies for temporal data

## ğŸ¯ Tasks

### Task 1: Opening Weekend Gross Prediction

**Objective**: Predict a movie's opening weekend box office performance using pre-release information.

**Approach**:
- **Models**: Ridge Regression, Lasso Regression, Random Forest, XGBoost, LightGBM
- **Features**: Production budget, genre, cast/crew, synopsis analysis, seasonal factors
- **Validation**: K-fold cross-validation with temporal considerations
- **Metrics**: RÂ², RMSE, MAE, MAPE

**Key Insights**:
- Production budget is the strongest predictor
- Genre and seasonal release timing significantly impact performance
- Star power (top actors/directors) provides moderate predictive value
- Synopsis sentiment and keyword analysis offer additional insights

### Task 2: Time Series Gross Prediction

**Objective**: Forecast daily box office revenue for movies currently in theaters.

**Approach**:
- **Model**: Custom Sequence-to-Sequence (Seq2Seq) architecture with attention mechanism
- **Framework**: PyTorch with LSTM encoders and decoders
- **Features**: Historical performance, temporal patterns, static movie attributes
- **Prediction Horizon**: 26 days (days 15-40 of theatrical run)
- **Training Strategy**: Time-based train/test split to simulate real-world deployment

**Architecture Highlights**:
- **Encoder**: Processes known performance data (first 14 days) and static features
- **Decoder**: Generates future predictions with attention over encoder outputs
- **Attention Mechanism**: Multi-head attention for focusing on relevant historical patterns
- **Regularization**: Dropout, gradient clipping, and early stopping

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- Jupyter Notebook or JupyterLab
- Git

### Environment Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/BT4222.git
cd BT4222

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install required packages
pip install pandas numpy matplotlib seaborn scikit-learn
pip install xgboost lightgbm torch torchvision torchaudio
pip install nltk beautifulsoup4 cloudscraper requests
pip install statsmodels tqdm jupyter
```

### Additional Setup

```python
# Download NLTK data (run in Python)
import nltk
nltk.download('stopwords')
nltk.download('punkt')
```

## ğŸ’» Usage

### Quick Start

1. **Data Collection** (Optional - datasets are provided):
   ```bash
   # Run preprocessing notebooks in order
   jupyter notebook Preprocessing/step1_theNumbers_scraping_daily_gross_2020_2025.ipynb
   # Continue with steps 2-4...
   ```

2. **Opening Weekend Prediction**:
   ```bash
   jupyter notebook "Opening Weekend Gross prediction/opening_weekend_gross_prediction.ipynb"
   ```

3. **Time Series Prediction**:
   ```bash
   jupyter notebook "Time Series Gross Prediction/TimeSeriesMovieGrossPrediction.ipynb"
   ```

### Notebook Execution Tips

- **Memory Requirements**: Time series model requires ~8GB RAM for full dataset
- **GPU Support**: CUDA-compatible GPU recommended for time series training
- **Execution Time**: Full pipeline takes 2-4 hours depending on hardware
- **Data Loading**: Some notebooks load data from Google Drive links

### Configuration Options

Key parameters can be adjusted in the notebooks:

```python
# Opening Weekend Prediction
TOP_N_ACTORS = 150          # Number of top actors to consider
TOP_N_COMPANIES = 200       # Top production companies
MAX_SYNOPSIS_FEATURES = 1000 # TF-IDF features for synopsis

# Time Series Prediction
N_DAYS_KNOWN = 14           # Known performance period
N_DAYS_PREDICT = 26         # Prediction horizon
EMBEDDING_DIM = 64          # Categorical embedding dimension
ENCODER_LSTM_UNITS = 128    # LSTM hidden units
```

## ğŸ”¬ Methodology

### Data Collection Strategy

1. **Primary Scraping**: Daily box office data from The Numbers (2020-2025)
2. **Metadata Enhancement**: TMDB API for cast, crew, and production details
3. **Historical Expansion**: Extended dataset to 2000-2025 for more training data
4. **Data Validation**: Cross-reference with Wikipedia for accuracy verification

### Feature Engineering Pipeline

```python
# Example feature engineering workflow
def create_features(df):
    # Temporal features
    df['is_weekend'] = df['release_date'].dt.dayofweek.isin([5, 6])
    df['release_month'] = df['release_date'].dt.month
    df['days_since_release'] = (df['date'] - df['release_date']).dt.days
    
    # Financial features
    df['budget_log'] = np.log1p(df['budget'])
    df['gross_per_theater'] = df['gross'] / df['theater_count']
    
    # Text features
    tfidf = TfidfVectorizer(max_features=1000, stop_words='english')
    synopsis_features = tfidf.fit_transform(df['synopsis'])
    
    return df
```

### Model Development

#### Opening Weekend Prediction
1. **Baseline Models**: Linear regression with basic features
2. **Advanced Models**: Ensemble methods with engineered features
3. **Hyperparameter Tuning**: Grid search with cross-validation
4. **Feature Selection**: Recursive feature elimination and importance analysis

#### Time Series Prediction
1. **Sequence Modeling**: LSTM-based encoder-decoder architecture
2. **Attention Mechanism**: Multi-head attention for temporal dependencies
3. **Regularization**: Comprehensive overfitting prevention
4. **Training Strategy**: Custom loss functions and learning rate scheduling

### Evaluation Methodology

- **Temporal Validation**: Train on older movies, test on newer releases
- **Multiple Metrics**: RÂ², RMSE, MAE, MAPE for comprehensive evaluation
- **Statistical Significance**: Confidence intervals and hypothesis testing
- **Business Impact**: Translation of model performance to real-world value

## ğŸ“ˆ Results

### Opening Weekend Prediction Performance

| Model | RÂ² Score | RMSE (M$) | MAE (M$) | MAPE (%) |
|-------|----------|-----------|----------|----------|
| Ridge Regression | 0.72 | **8.5** | **5.2** | **35.2** |
| Random Forest | 0.78 | 7.8 | 4.9 | 32.1 |
| XGBoost | 0.81 | 7.1 | 4.3 | 29.8 |
| **LightGBM** | **0.83** | 6.8 | 4.1 | 28.5 |

### Time Series Prediction Performance

| Metric | Value | Business Impact |
|--------|-------|-----------------|
| **RMSE** | $2.3M | Enables accurate revenue forecasting |
| **MAE** | $1.8M | Reliable daily performance tracking |
| **MAPE** | 15.2% | Industry-competitive accuracy |
| **RÂ²** | 0.89 | Strong explanatory power |

### Key Findings

1. **Opening Weekend Drivers**:
   - Production budget explains 60% of variance
   - Genre and seasonal timing contribute 15% additional predictive power
   - Star power and marketing provide marginal improvements

2. **Time Series Patterns**:
   - Strong weekly seasonality (weekends vs. weekdays)
   - Exponential decay pattern in daily gross over time
   - Holiday periods show significant anomalies

3. **Model Insights**:
   - Ensemble methods consistently outperform single algorithms
   - Deep learning excels at capturing temporal dependencies
   - Feature engineering provides larger gains than model complexity

## ğŸ› ï¸ Technical Architecture

### Opening Weekend Prediction Pipeline
```
Raw Data â†’ Feature Engineering â†’ Model Training â†’ Prediction
    â†“              â†“                   â†“             â†“
Scraped Data â†’ TF-IDF + OHE â†’ Grid Search CV â†’ Revenue Forecast
```

### Time Series Architecture
```
Static Features â”€â”€â”¬â”€â†’ Encoder â”€â”€â†’ Context Vector â”€â”€â”¬â”€â†’ Decoder â”€â”€â†’ Predictions
                  â”‚                                 â”‚
Historical Data â”€â”€â”˜                                 â”‚
                                                    â”‚
Future Time Features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”˜
```

## ğŸ¤ Contributing

We welcome contributions to improve the project! Here's how you can help:

### Areas for Improvement
- **Data Sources**: Integration of additional movie databases
- **Feature Engineering**: Novel feature creation techniques
- **Model Architectures**: Advanced deep learning approaches
- **Evaluation Metrics**: Business-specific performance measures

### Contribution Guidelines
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Code Standards
- Follow PEP 8 style guidelines
- Include comprehensive docstrings
- Add unit tests for new functionality
- Update documentation as needed

## ğŸ“š References

### Academic Sources
- Box office prediction literature review
- Time series forecasting methodologies
- Web scraping best practices
- Deep learning for sequential data

### Data Sources
- [The Numbers](https://www.the-numbers.com/) - Box office database
- [TMDB](https://www.themoviedb.org/) - Movie metadata API
- [Wikipedia](https://www.wikipedia.org/) - Additional movie information

### Technical Resources
- PyTorch documentation for sequence modeling
- scikit-learn user guide for machine learning
- Beautiful Soup and CloudScraper for web scraping

## ğŸ“„ License

This project is developed for educational purposes as part of the BT4222 course at NUS. The code is available under the MIT License, but please respect the terms of service of the data sources used.

## ğŸ‘¥ Authors

**BT4222 Project Team**
- Course: BT4222 Mining Web Data for Business Insights
- Institution: National University of Singapore (NUS)
- Academic Year: 2024-2025

## ğŸ™ Acknowledgments

- **Course Instructors**: For guidance and project framework
- **Data Providers**: The Numbers, TMDB, and Wikipedia for accessible data
- **Open Source Community**: For the excellent libraries and tools used
- **NUS**: For providing the academic environment and computational resources

---

*For questions or issues, please refer to the project documentation or contact the development team.*
